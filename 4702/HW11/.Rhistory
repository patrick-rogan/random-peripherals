tfz2 = data.frame(tempFrame[!train,])
tempFrame = data.frame(simDat[,1],tempFrame)
tempFrame = tempFrame[train,]
colnames(tempFrame)[1] = "Y"
attach(tempFrame)
lm.fit = lm(Y ~., tempFrame, subset = train)
lm.p = unname(predict(lm.fit, tfz))
lm.p2 = unname(predict(lm.fit,tfz2))
trainMSE[i] =  mean((simDat$Y[train]-lm.p)^2)
testMSE[i] =  mean((simDat$Y[!train]-lm.p2)^2)
}
plot(c(1:20),trainMSE, xlab = "Number of Predictors", ylab = "Training MSE",
main = "Training MSE vs Number of Predictors")
plot(c(7:20),testMSE[7:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
plot(c(1:20),testMSE[1:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
plot(c(2:20),testMSE[2:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
plot(c(5:20),testMSE[5:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
plot(c(3:20),testMSE[3:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
plot(c(2:20),testMSE[2:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
plot(c(4:20),testMSE[4:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
set.seed(1)
X = matrix(0,nrow = 1000, ncol = 20)
meanVec = c(0,20,2,0.25,100,14,1,0,10,18,2,0.75,2,3,-18,18^3,2^3,3^3,0.9^3,-44^3)
sdVec = c(1,.7,1,5,.5,.2,.8,.1,.2,3,2,5,1,9,3,1.1,2.4,2.1,3,0.2)
eps = rnorm(1000, mean = 0, sd = 2.0)
betaVect = c(0,1,4,0,11,1,6,1,1,7,0,3,4,2,20,1,7,9,0,18)
beta0 = 3
Y = beta0 + eps
for (i in 1:20){
X[,i] = rnorm(1000, mean = meanVec[i], sd = sdVec[i])
Y = Y + betaVect[i]*X[,i]
}
simDat = data.frame(Y,X)
colnames(simDat) = c("Y","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11","X12",
"X13","X14","X15","X16","X17","X18","X19","X20")
# Part B
library(caret)
train.ix = as.integer(createDataPartition(simDat[,1], p = .9, list = FALSE, times = 1))
train = rep(FALSE,length(simDat[,1]))
train[train.ix] = TRUE
simDat.test = simDat[!train,]
# Part C
library(leaps)
attach(simDat)
regfit.full = regsubsets(Y~., simDat, subset = train,nvmax = 20)
summary(regfit.full)
trainMSE = rep(0,20)
testMSE = rep(0,20)
for (i in c(1:20)){
tempFrame = simDat[colnames(simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]]
tfz = data.frame(tempFrame[train,])
tfz2 = data.frame(tempFrame[!train,])
tempFrame = data.frame(simDat[,1],tempFrame)
tempFrame = tempFrame[train,]
colnames(tempFrame)[1] = "Y"
attach(tempFrame)
lm.fit = lm(Y ~., tempFrame, subset = train)
lm.p = unname(predict(lm.fit, tfz))
lm.p2 = unname(predict(lm.fit,tfz2))
trainMSE[i] =  mean((simDat$Y[train]-lm.p)^2)
testMSE[i] =  mean((simDat$Y[!train]-lm.p2)^2)
}
plot(c(1:20),trainMSE, xlab = "Number of Predictors", ylab = "Training MSE",
main = "Training MSE vs Number of Predictors")
plot(c(4:20),testMSE[4:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
set.seed(1)
X = matrix(0,nrow = 1000, ncol = 20)
meanVec = c(0,20,2,0.25,100,14,1,0,10,18,2,0.75,2,3,-18,18^3,2^3,3^3,0.9^3,-44^3)
sdVec = c(1,.7,1,5,.5,.2,.8,.1,.2,3,2,5,1,9,3,1.1^3,2.4^3,2.1^3,3^3,0.2^3)
eps = rnorm(1000, mean = 0, sd = 2.0)
betaVect = c(0,1,4,0,11,1,6,1,1,7,0,3,4,2,20,1,7,9,0,18)
beta0 = 3
Y = beta0 + eps
for (i in 1:20){
X[,i] = rnorm(1000, mean = meanVec[i], sd = sdVec[i])
Y = Y + betaVect[i]*X[,i]
}
simDat = data.frame(Y,X)
colnames(simDat) = c("Y","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11","X12",
"X13","X14","X15","X16","X17","X18","X19","X20")
# Part B
library(caret)
train.ix = as.integer(createDataPartition(simDat[,1], p = .9, list = FALSE, times = 1))
train = rep(FALSE,length(simDat[,1]))
train[train.ix] = TRUE
simDat.test = simDat[!train,]
# Part C
library(leaps)
attach(simDat)
regfit.full = regsubsets(Y~., simDat, subset = train,nvmax = 20)
summary(regfit.full)
trainMSE = rep(0,20)
testMSE = rep(0,20)
for (i in c(1:20)){
tempFrame = simDat[colnames(simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]]
tfz = data.frame(tempFrame[train,])
tfz2 = data.frame(tempFrame[!train,])
tempFrame = data.frame(simDat[,1],tempFrame)
tempFrame = tempFrame[train,]
colnames(tempFrame)[1] = "Y"
attach(tempFrame)
lm.fit = lm(Y ~., tempFrame, subset = train)
lm.p = unname(predict(lm.fit, tfz))
lm.p2 = unname(predict(lm.fit,tfz2))
trainMSE[i] =  mean((simDat$Y[train]-lm.p)^2)
testMSE[i] =  mean((simDat$Y[!train]-lm.p2)^2)
}
plot(c(1:20),trainMSE, xlab = "Number of Predictors", ylab = "Training MSE",
main = "Training MSE vs Number of Predictors")
plot(c(4:20),testMSE[4:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
X = matrix(0,nrow = 1000, ncol = 20)
set.seed(1)
X = matrix(0,nrow = 1000, ncol = 20)
meanVec = c(0,20,2,0.25,100,14,1,0,10,99,2,0.75,2,3,-18,18,2,3,0.9,-80)
sdVec = c(1,.7,1,5,.5,.2,.8,.1,.2,3,2,5,1,9,3,1.1,2.4,2.1,3,0.2)
eps = rnorm(1000, mean = 0, sd = 2.0)
betaVect = c(0,1,4,0,11,1,6,1,1,7,0,3,4,2,20,1,7,9,0,18)
beta0 = 3
Y = beta0 + eps
for (i in 1:20){
X[,i] = rnorm(1000, mean = meanVec[i], sd = sdVec[i])
Y = Y + betaVect[i]*X[,i]
}
#for (i in 16:20){
#  X[,i] = rnorm(1000, mean = meanVec[i], sd = sdVec[i])
#  Y = Y + betaVect[i]*X[,i]^3
#}
simDat = data.frame(Y,X)
colnames(simDat) = c("Y","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11","X12",
"X13","X14","X15","X16","X17","X18","X19","X20")
# Part B
library(caret)
train.ix = as.integer(createDataPartition(simDat[,1], p = .9, list = FALSE, times = 1))
train = rep(FALSE,length(simDat[,1]))
train[train.ix] = TRUE
simDat.test = simDat[!train,]
# Part C
library(leaps)
attach(simDat)
regfit.full = regsubsets(Y~., simDat, subset = train,nvmax = 20)
summary(regfit.full)
trainMSE = rep(0,20)
testMSE = rep(0,20)
for (i in c(1:20)){
tempFrame = simDat[colnames(simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]]
tfz = data.frame(tempFrame[train,])
tfz2 = data.frame(tempFrame[!train,])
tempFrame = data.frame(simDat[,1],tempFrame)
tempFrame = tempFrame[train,]
colnames(tempFrame)[1] = "Y"
attach(tempFrame)
lm.fit = lm(Y ~., tempFrame, subset = train)
lm.p = unname(predict(lm.fit, tfz))
lm.p2 = unname(predict(lm.fit,tfz2))
trainMSE[i] =  mean((simDat$Y[train]-lm.p)^2)
testMSE[i] =  mean((simDat$Y[!train]-lm.p2)^2)
}
plot(c(1:20),trainMSE, xlab = "Number of Predictors", ylab = "Training MSE",
main = "Training MSE vs Number of Predictors")
plot(c(4:20),testMSE[4:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
which.min(testMSE)
testMSE
set.seed(1)
X = matrix(0,nrow = 1000, ncol = 20)
meanVec = c(0,120,2,0.25,100,14,1,0,10,99,2,0.75,2,3,-180,18,2,3,0.9,-80)
sdVec = c(1,.7,1,5,.5,.2,.8,.1,.2,3,2,5,1,9,3,1.1,2.4,2.1,3,0.2)
eps = rnorm(1000, mean = 0, sd = 2.0)
betaVect = c(0,1,4,0,11,1,6,1,1,7,0,3,4,2,20,1,7,9,0,18)
beta0 = 3
Y = beta0 + eps
for (i in 1:20){
X[,i] = rnorm(1000, mean = meanVec[i], sd = sdVec[i])
Y = Y + betaVect[i]*X[,i]
}
simDat = data.frame(Y,X)
colnames(simDat) = c("Y","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11","X12",
"X13","X14","X15","X16","X17","X18","X19","X20")
# Part B
library(caret)
train.ix = as.integer(createDataPartition(simDat[,1], p = .9, list = FALSE, times = 1))
train = rep(FALSE,length(simDat[,1]))
train[train.ix] = TRUE
simDat.test = simDat[!train,]
# Part C
library(leaps)
attach(simDat)
regfit.full = regsubsets(Y~., simDat, subset = train,nvmax = 20)
summary(regfit.full)
trainMSE = rep(0,20)
testMSE = rep(0,20)
for (i in c(1:20)){
tempFrame = simDat[colnames(simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]]
tfz = data.frame(tempFrame[train,])
tfz2 = data.frame(tempFrame[!train,])
tempFrame = data.frame(simDat[,1],tempFrame)
tempFrame = tempFrame[train,]
colnames(tempFrame)[1] = "Y"
attach(tempFrame)
lm.fit = lm(Y ~., tempFrame, subset = train)
lm.p = unname(predict(lm.fit, tfz))
lm.p2 = unname(predict(lm.fit,tfz2))
trainMSE[i] =  mean((simDat$Y[train]-lm.p)^2)
testMSE[i] =  mean((simDat$Y[!train]-lm.p2)^2)
}
plot(c(1:20),trainMSE, xlab = "Number of Predictors", ylab = "Training MSE",
main = "Training MSE vs Number of Predictors")
plot(c(4:20),testMSE[4:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
which.min(testMSE)
testMSE
X = matrix(0,nrow = 1000, ncol = 20)
meanVec = c(0,120,2,0.25,100,14,1,0,10,99,2,0.75,2000,3,-180,18,2,3,0.9,-80)
sdVec = c(1,.7,1,5,.5,.2,.8,.1,.2,3,2,5,1,9,3,1.1,2.4,2.1,3,0.2)
eps = rnorm(1000, mean = 0, sd = 2.0)
betaVect = c(0,1,4,0,11,1,6,1,1,7,0,3,4,2,20,1,7,9,0,18)
beta0 = 3
Y = beta0 + eps
for (i in 1:20){
X[,i] = rnorm(1000, mean = meanVec[i], sd = sdVec[i])
Y = Y + betaVect[i]*X[,i]
}
#for (i in 16:20){
#  X[,i] = rnorm(1000, mean = meanVec[i], sd = sdVec[i])
#  Y = Y + betaVect[i]*X[,i]^3
#}
simDat = data.frame(Y,X)
colnames(simDat) = c("Y","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11","X12",
"X13","X14","X15","X16","X17","X18","X19","X20")
# Part B
library(caret)
train.ix = as.integer(createDataPartition(simDat[,1], p = .9, list = FALSE, times = 1))
train = rep(FALSE,length(simDat[,1]))
train[train.ix] = TRUE
simDat.test = simDat[!train,]
# Part C
library(leaps)
attach(simDat)
regfit.full = regsubsets(Y~., simDat, subset = train,nvmax = 20)
summary(regfit.full)
trainMSE = rep(0,20)
testMSE = rep(0,20)
for (i in c(1:20)){
tempFrame = simDat[colnames(simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]]
tfz = data.frame(tempFrame[train,])
tfz2 = data.frame(tempFrame[!train,])
tempFrame = data.frame(simDat[,1],tempFrame)
tempFrame = tempFrame[train,]
colnames(tempFrame)[1] = "Y"
attach(tempFrame)
lm.fit = lm(Y ~., tempFrame, subset = train)
lm.p = unname(predict(lm.fit, tfz))
lm.p2 = unname(predict(lm.fit,tfz2))
trainMSE[i] =  mean((simDat$Y[train]-lm.p)^2)
testMSE[i] =  mean((simDat$Y[!train]-lm.p2)^2)
}
plot(c(1:20),trainMSE, xlab = "Number of Predictors", ylab = "Training MSE",
main = "Training MSE vs Number of Predictors")
plot(c(4:20),testMSE[4:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
which.min(testMSE)
testMSE
set.seed(1)
X = matrix(0,nrow = 1000, ncol = 20)
meanVec = c(0,120,2,0.25,100,14,1,0,10,99,2,0.75,2000,3,-180,18,2,3,0.9,-80)
sdVec = c(1,.7,1,5,.5,.2,.8,.1,.2,3,2,5,1,9,3,1.1,2.4,2.1,3,0.2)
eps = rnorm(1000, mean = 0, sd = 2.0)
betaVect = c(0,1,4,0,100,1,6,170,1,70,0,3,4,2,200,1,7,9,0,18)
beta0 = 3
Y = beta0 + eps
for (i in 1:20){
X[,i] = rnorm(1000, mean = meanVec[i], sd = sdVec[i])
Y = Y + betaVect[i]*X[,i]
}
simDat = data.frame(Y,X)
colnames(simDat) = c("Y","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11","X12",
"X13","X14","X15","X16","X17","X18","X19","X20")
# Part B
library(caret)
train.ix = as.integer(createDataPartition(simDat[,1], p = .9, list = FALSE, times = 1))
train = rep(FALSE,length(simDat[,1]))
train[train.ix] = TRUE
simDat.test = simDat[!train,]
# Part C
library(leaps)
attach(simDat)
regfit.full = regsubsets(Y~., simDat, subset = train,nvmax = 20)
summary(regfit.full)
trainMSE = rep(0,20)
testMSE = rep(0,20)
for (i in c(1:20)){
tempFrame = simDat[colnames(simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]]
tfz = data.frame(tempFrame[train,])
tfz2 = data.frame(tempFrame[!train,])
tempFrame = data.frame(simDat[,1],tempFrame)
tempFrame = tempFrame[train,]
colnames(tempFrame)[1] = "Y"
attach(tempFrame)
lm.fit = lm(Y ~., tempFrame, subset = train)
lm.p = unname(predict(lm.fit, tfz))
lm.p2 = unname(predict(lm.fit,tfz2))
trainMSE[i] =  mean((simDat$Y[train]-lm.p)^2)
testMSE[i] =  mean((simDat$Y[!train]-lm.p2)^2)
}
plot(c(1:20),trainMSE, xlab = "Number of Predictors", ylab = "Training MSE",
main = "Training MSE vs Number of Predictors")
plot(c(4:20),testMSE[4:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
which.min(testMSE)
testMSE
set.seed(1)
X = matrix(0,nrow = 1000, ncol = 20)
meanVec = c(0,120,2,0.25,100,14,1,0,10,99,2,100,2000,3,-180,18,2,3,0.9,-80)
sdVec = c(1,.7,1,5,.5,.2,.8,.1,.2,3,2,5,1,9,3,1.1,2.4,2.1,3,0.2)
eps = rnorm(1000, mean = 0, sd = 2.0)
betaVect = c(0,1,4,0,100,1,6,170,1,70,0,300,4,2,200,1,7,9,0,18)
beta0 = 3
Y = beta0 + eps
for (i in 1:20){
X[,i] = rnorm(1000, mean = meanVec[i], sd = sdVec[i])
Y = Y + betaVect[i]*X[,i]
}
#for (i in 16:20){
#  X[,i] = rnorm(1000, mean = meanVec[i], sd = sdVec[i])
#  Y = Y + betaVect[i]*X[,i]^3
#}
simDat = data.frame(Y,X)
colnames(simDat) = c("Y","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11","X12",
"X13","X14","X15","X16","X17","X18","X19","X20")
# Part B
library(caret)
train.ix = as.integer(createDataPartition(simDat[,1], p = .9, list = FALSE, times = 1))
train = rep(FALSE,length(simDat[,1]))
train[train.ix] = TRUE
simDat.test = simDat[!train,]
# Part C
library(leaps)
attach(simDat)
regfit.full = regsubsets(Y~., simDat, subset = train,nvmax = 20)
summary(regfit.full)
trainMSE = rep(0,20)
testMSE = rep(0,20)
for (i in c(1:20)){
tempFrame = simDat[colnames(simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]]
tfz = data.frame(tempFrame[train,])
tfz2 = data.frame(tempFrame[!train,])
tempFrame = data.frame(simDat[,1],tempFrame)
tempFrame = tempFrame[train,]
colnames(tempFrame)[1] = "Y"
attach(tempFrame)
lm.fit = lm(Y ~., tempFrame, subset = train)
lm.p = unname(predict(lm.fit, tfz))
lm.p2 = unname(predict(lm.fit,tfz2))
trainMSE[i] =  mean((simDat$Y[train]-lm.p)^2)
testMSE[i] =  mean((simDat$Y[!train]-lm.p2)^2)
}
plot(c(1:20),trainMSE, xlab = "Number of Predictors", ylab = "Training MSE",
main = "Training MSE vs Number of Predictors")
plot(c(4:20),testMSE[4:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
which.min(testMSE)
set.seed(1)
X = matrix(0,nrow = 1000, ncol = 20)
meanVec = c(0,120,2,0.25,100,14,1,0,10,99,2,100,2000,3,180,18,0,0,0,0)
sdVec = c(1,.7,1,5,.5,.2,.8,.1,.2,3,2,5,1,9,3,1.1,2.4,2.1,3,0.2)
eps = rnorm(1000, mean = 0, sd = 2.0)
betaVect = c(0,1,4,0,100,1,6,170,1,70,0,100,4,2,200,1,7,0,0,0)
beta0 = 3
Y = beta0 + eps
for (i in 1:20){
X[,i] = rnorm(1000, mean = meanVec[i], sd = sdVec[i])
Y = Y + betaVect[i]*X[,i]
}
simDat = data.frame(Y,X)
colnames(simDat) = c("Y","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11","X12",
"X13","X14","X15","X16","X17","X18","X19","X20")
# Part B
library(caret)
train.ix = as.integer(createDataPartition(simDat[,1], p = .9, list = FALSE, times = 1))
train = rep(FALSE,length(simDat[,1]))
train[train.ix] = TRUE
simDat.test = simDat[!train,]
# Part C
library(leaps)
attach(simDat)
regfit.full = regsubsets(Y~., simDat, subset = train,nvmax = 20)
summary(regfit.full)
trainMSE = rep(0,20)
testMSE = rep(0,20)
for (i in c(1:20)){
tempFrame = simDat[colnames(simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]]
tfz = data.frame(tempFrame[train,])
tfz2 = data.frame(tempFrame[!train,])
tempFrame = data.frame(simDat[,1],tempFrame)
tempFrame = tempFrame[train,]
colnames(tempFrame)[1] = "Y"
attach(tempFrame)
lm.fit = lm(Y ~., tempFrame, subset = train)
lm.p = unname(predict(lm.fit, tfz))
lm.p2 = unname(predict(lm.fit,tfz2))
trainMSE[i] =  mean((simDat$Y[train]-lm.p)^2)
testMSE[i] =  mean((simDat$Y[!train]-lm.p2)^2)
}
plot(c(1:20),trainMSE, xlab = "Number of Predictors", ylab = "Training MSE",
main = "Training MSE vs Number of Predictors")
plot(c(4:20),testMSE[4:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
which.min(testMSE)
testMSE
plot(c(1:20),trainMSE, xlab = "Number of Predictors", ylab = "Training MSE",
main = "Training MSE vs Number of Predictors")
main = "Training MSE vs Number of Predictors")
plot(c(4:20),testMSE[4:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
tempFrame = simDat[colnames(simDat[,-1])[summary(regfit.full)$which[12,c(2:21)]]]
tfz = data.frame(tempFrame[train,])
tfz2 = data.frame(tempFrame[!train,])
tempFrame = data.frame(simDat[,1],tempFrame)
tempFrame = tempFrame[train,]
colnames(tempFrame)[1] = "Y"
attach(tempFrame)
lm.fit = lm(Y ~., tempFrame, subset = train)
lm.fit
summary(lm.fit)
lm.fit
simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]
summary(regfit.full)$which[i,c(2:21)
summary(regfit.full)$which[i,c(2:21)]
summary(regfit.full)$which[12,c(2:21)]
betaVect[simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]
betaVect[simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]]
betaVect*
simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]
simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]]
simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]
[summary(regfit.full)$which[i,c(2:21)]]
summary(regfit.full)$which[i,c(2:21)]
betaVect[summary(regfit.full)$which[12,c(2:21)]]
lm.fit
lm.fit - betaVect[summary(regfit.full)$which[12,c(2:21)]]
unname(lm.fit) - betaVect[summary(regfit.full)$which[12,c(2:21)]]
unname(lm.fit)
lm.fit$coefficients
unname(lm.fit$coefficients)
unname(lm.fit$coefficients) - betaVect[summary(regfit.full)$which[12,c(2:21)]]
unname(lm.fit$coefficients[-1]) - betaVect[summary(regfit.full)$which[12,c(2:21)]]
betav = unname(lm.fit$coefficients[-1]) - betaVect[summary(regfit.full)$which[12,c(2:21)]]
betav
betav%*%betav
sqrt(betav%*%betav)
for (i in c(1:20)){
tempFrame = simDat[colnames(simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]]
tfz = data.frame(tempFrame[train,])
tfz2 = data.frame(tempFrame[!train,])
tempFrame = data.frame(simDat[,1],tempFrame)
tempFrame = tempFrame[train,]
colnames(tempFrame)[1] = "Y"
attach(tempFrame)
lm.fit = lm(Y ~., tempFrame, subset = train)
betav= unname(lm.fit$coefficients[-1]) - betaVect[summary(regfit.full)$which[i,c(2:21)]]
delBeta[i] = sqrt(betav%*%betav)
lm.p = unname(predict(lm.fit, tfz))
lm.p2 = unname(predict(lm.fit,tfz2))
trainMSE[i] =  mean((simDat$Y[train]-lm.p)^2)
testMSE[i] =  mean((simDat$Y[!train]-lm.p2)^2)
}
delBeta = rep(0,20)
for (i in c(1:20)){
tempFrame = simDat[colnames(simDat[,-1])[summary(regfit.full)$which[i,c(2:21)]]]
tfz = data.frame(tempFrame[train,])
tfz2 = data.frame(tempFrame[!train,])
tempFrame = data.frame(simDat[,1],tempFrame)
tempFrame = tempFrame[train,]
colnames(tempFrame)[1] = "Y"
attach(tempFrame)
lm.fit = lm(Y ~., tempFrame, subset = train)
betav= unname(lm.fit$coefficients[-1]) - betaVect[summary(regfit.full)$which[i,c(2:21)]]
delBeta[i] = sqrt(betav%*%betav)
lm.p = unname(predict(lm.fit, tfz))
lm.p2 = unname(predict(lm.fit,tfz2))
trainMSE[i] =  mean((simDat$Y[train]-lm.p)^2)
testMSE[i] =  mean((simDat$Y[!train]-lm.p2)^2)
}
plot(c(4:20),delBeta[4:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
plot(c(1:20),delBeta[1:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors",sub = "Models with < 7 Predictors Excluded due to Scale")
min(delBeta)
which.min(delBeta)
par(mar=c(5.1,4.7,4.1,2.1))
plot(c(1:20),delBeta[1:20], xlab = "Number of Predictors", ylab = "Test MSE",
main = "Test MSE vs Number of Predictors")
plot(c(1:20),delBeta[1:20], xlab = "Number of Predictors", ylab = expression(sqrt(sum(beta[j]-hat(beta[j]^r))^2)),
main = "Test MSE vs Number of Predictors")
par(mar=c(5.1,5.1,4.1,2.1))
plot(c(1:20),delBeta[1:20], xlab = "Number of Predictors", ylab = expression(sqrt(sum(beta[j]-hat(beta[j]^r))^2)),
main = "Test MSE vs Number of Predictors")
plot(c(1:20),delBeta[1:20], xlab = "Number of Predictors", ylab = expression(sqrt(sum((beta[j]-hat(beta[j]^r)))^2)),
main = "Test MSE vs Number of Predictors")
plot(c(1:20),delBeta[1:20], xlab = "Number of Predictors", ylab = expression(sqrt(sum((beta[j]-hat(beta[j]^r)))^2)),
main = expression(paste(sqrt(sum((beta[j]-hat(beta[j]^r)))^2), " vs Number of Predictors"))
plot(c(1:20),delBeta[1:20], xlab = "Number of Predictors", ylab = expression(sqrt(sum((beta[j]-hat(beta[j]^r)))^2)),
main = expression(paste(sqrt(sum((beta[j]-hat(beta[j]^r)))^2), " vs Number of Predictors")))
